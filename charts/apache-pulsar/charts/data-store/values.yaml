globalData:
  ## @param globalData.name [string] String to name component
  ##
  name: "data-store"

  ## @param globalData.fullnameOverride [string,nullable] String to fully override component naming
  ##
  fullnameOverride:

  ## @param globalData.replicas The number of bookies to deploy
  ##
  replicas: 3

## @section Certificate Resources
## @descriptionStart
## Configure the component's certificate
## @descriptionEnd
##
certificateResources:

  ## @param certificateResources.tlsSecretName [string,nullable]
  ##
  tlsSecretName:

  ## @param certificateResources.jksPasswordSecretName [string,nullable]
  ##
  jksPasswordSecretName:

  ## @extra certificateResources.certificateRequest Refer to the [CertificateSpec](https://cert-manager.io/docs/reference/api-docs/#cert-manager.io/v1.CertificateSpec) for more info about these values.
  ##
  certificateRequest:

    ## @param certificateResources.certificateRequest.renewBefore How long before the currently issued certificate’s expiry cert-manager should renew the certificate. Default is 2/3 of the duration.
    ##
    renewBefore:

    ## @param certificateResources.certificateRequest.duration The requested ‘duration’ (i.e. lifetime) of the Certificate. Default is 90 days
    ##
    duration:

    ##
    ##
    subject:

      ## @param certificateResources.certificateRequest.subject.organizations [array,nullable] Organizations to be used on the Certificate
      ##
      organizations: []

    ## @param certificateResources.certificateRequest.privateKey [object,nullable] Options to control private keys used for the Certificate
    ##
    privateKey: {}

    ## @param certificateResources.certificateRequest.issuerRef [object,nullable] IssuerRef is a reference to the issuer for this certificate
    ##
    issuerRef: {}

## @section Pulsar Environment Configuration
## @descriptionStart

## @descriptionEnd
##
pulsarEnv:
  ## @param pulsarEnv.confPath The full path where configuration files are held
  ##
  confPath: /pulsar/conf
  ## @param pulsarEnv.gc A collection of JVM settings garbage collection settings
  ##
  gc:
    - "-XX:+UseG1GC"
    - "-XX:MaxGCPauseMillis=10"
    - "-XX:+ParallelRefProcEnabled"
    - "-XX:+UnlockExperimentalVMOptions"
    - "-XX:+DoEscapeAnalysis"
    - "-XX:ParallelGCThreads=32"
    - "-XX:ConcGCThreads=32"
    - "-XX:G1NewSizePercent=50"
    - "-XX:+DisableExplicitGC"
  ## @param pulsarEnv.mem A collection of JVM memory settings
  ##
  mem:
    - "-Xms2g"
    - "-Xmx2g"
    - "-XX:MaxDirectMemorySize=4g"

  ##
  ##
  loggingLevels:
    ## @param pulsarEnv.loggingLevels.root Applies the pulsar.log.root.level JVM option
    ##
    root: "error"
    ## @param pulsarEnv.loggingLevels.pulsar Applies the PULSAR_LOG_LEVEL env var
    ##
    pulsar: "error"

  ## @param pulsarEnv.extraOpts A collection of extra options to be passed to the jvm. Format each as the entire key/value
  ##
  extraOpts:
    - "-Dzookeeper.tcpKeepAlive=true"
    - "-Dzookeeper.clientTcpKeepAlive=true"
    - "-Dpulsar.allocator.exit_on_oom=true"
    - "-Dio.netty.recycler.maxCapacity.default=1000"
    - "-Dio.netty.recycler.linkCapacity=1024"
    - "-Dlog4j2.formatMsgNoLookups=true"
    - "-Dio.netty.leakDetectionLevel=disabled"

  ## @param pulsarEnv.extraClasspath A collection of extra paths for the pulsar classpath. Include just the folder or file path, no delimiter.
  ##
  extraClasspath: []
  ## @param pulsarEnv.stopTimeout Time to wait for an instance to stop before getting forceful
  ##
  stopTimeout: 5

## @section Data store configuration
## @descriptionStart
## Configure data store settings. Refer to the [project's documentation](https://pulsar.apache.org/docs/next/reference-configuration-bookkeeper) for a full spec.
##
## > Note, the values not documented here are set by the parent chart
## @descriptionEnd
##

config:
  ## @skip config.advertisedAddress
  ## Configure a specific hostname or IP address that the bookie should use to advertise itself to clients. By default, the bookie advertises either its own IP address or hostname according to the listeningInterface and useHostNameAsBookieID settings.
  ##
  advertisedAddress:
  ## @skip config.allowEphemeralPorts
  ## Whether the bookie is allowed to use an ephemeral port (port 0) as its server port. By default, an ephemeral port is not allowed. Using an ephemeral port as the service port usually indicates a configuration error. However, in unit tests, using an ephemeral port will address port conflict problems and allow running tests in parallel.
  ##
  allowEphemeralPorts:
  ## @skip config.allowLoopback
  ## Whether the bookie is allowed to use a loopback interface as its primary interface (that is the interface used to establish its identity). By default, loopback interfaces are not allowed to work as the primary interface. Using a loopback interface as the primary interface usually indicates a configuration error. For example, it’s fairly common in some VPS setups to not configure a hostname or to have the hostname resolve to 127.0.0.1. If this is the case, then all bookies in the cluster will establish their identities as 127.0.0.1:3181 and only one will be able to join the cluster. For VPSs configured like this, you should explicitly set the listening interface.
  ##
  allowLoopback: FALSE
  ## @param config.allowMultipleDirsUnderSameDiskPartition Configure the bookie to enable/disable multiple ledger/index/journal directories in the same filesystem disk partition.
  ##
  allowMultipleDirsUnderSameDiskPartition:
  ## @param config.allowStorageExpansion Allow the bookie storage to expand. Newly added ledger and index dirs must be empty.
  ##
  allowStorageExpansion:
  ## @param config.auditorPeriodicBookieCheckInterval The interval between auditor bookie checks. The auditor bookie check, checks ledger metadata to see which bookies should contain entries for each ledger. If a bookie which should contain entries is unavailable, thea the ledger containing that entry is marked for recovery. Setting this to 0 disabled the periodic check. Bookie checks will still run when a bookie fails. The interval is specified in seconds.
  ##
  auditorPeriodicBookieCheckInterval: 86400
  ## @param config.auditorPeriodicCheckInterval Interval at which the auditor will do a check of all ledgers in the cluster. By default this runs once a week. The interval is set in seconds. To disable the periodic check completely, set this to 0. Note that periodic checking will put extra load on the cluster, so it should not be run more frequently than once a day.
  ##
  auditorPeriodicCheckInterval: 604800
  ## @param config.autoRecoveryDaemonEnabled Whether the bookie itself can start auto-recovery service.
  ##
  autoRecoveryDaemonEnabled: false
  ## @skip config.bookkeeperTLSClientAuthentication
  ##
  bookkeeperTLSClientAuthentication:
  ## @skip config.bookkeeperTLSTrustCertsFilePath
  ##
  bookkeeperTLSTrustCertsFilePath:
  ## @param config.bookieAuthProviderFactoryClass [string,nullable] The factory class name of the bookie authentication provider. If this is null, then there is no authentication.
  ##
  bookieAuthProviderFactoryClass:
  ## @param config.bookieDeathWatchInterval Interval to watch whether bookie is dead or not, in milliseconds
  ##
  bookieDeathWatchInterval: 1000
  ## @skip config.bookieId
  ## If you want to custom a bookie ID or use a dynamic network address for the bookie, you can set the bookieId. Bookie advertises itself using the bookieId rather than the BookieSocketAddress (hostname:port or IP:port). If you set the bookieId, then the useHostNameAsBookieID does not take effect. The bookieId is a non-empty string that can contain ASCII digits and letters ([a-zA-Z9-0]), colons, dashes, and dots. For more information about bookieId, [see here](http://bookkeeper.apache.org/bps/BP-41-bookieid/).
  ##
  bookieId:
  ## @skip config.bookiePort
  ## The port on which the bookie server listens.
  ##
  bookiePort:
  ## @param config.byteBufAllocatorSizeMax The maximum buf size of the received ByteBuf allocator.
  ##
  byteBufAllocatorSizeMax:
  ## @param config.compactionMaxOutstandingRequests Sets the maximum number of entries that can be compacted without flushing. When compacting, the entries are written to the entrylog and the new offsets are cached in memory. Once the entrylog is flushed the index is updated with the new offsets. This parameter controls the number of entries added to the entrylog before a flush is forced. A higher value for this parameter means more memory will be used for offsets. Each offset consists of 3 longs. This parameter should not be modified unless you’re fully aware of the consequences.
  ##
  compactionMaxOutstandingRequests: 100000
  ## @param config.compactionRate The rate at which compaction will read entries, in adds per second.
  ##
  compactionRate: 1000
  ## @param config.compactionRateByBytes Set the rate at which compaction reads entries. The unit is bytes added per second.
  ##
  compactionRateByBytes: 1000000
  ## @param config.compactionRateByEntries The rate at which compaction will read entries, in adds per second.
  ##
  compactionRateByEntries: 1000
  ## @param config.dbStorage_readAheadCacheBatchSize How many entries to pre-fill in cache after a read cache miss
  ##
  dbStorage_readAheadCacheBatchSize: 1000
  ## @param config.dbStorage_readAheadCacheMaxSizeMb [string,nullable] Size of Read cache. Memory is allocated from JVM direct memory. This read cache is pre-filled doing read-ahead whenever a cache miss happens. By default, it is allocated to 25% of the available direct memory.
  ##
  dbStorage_readAheadCacheMaxSizeMb:
  ## @param config.dbStorage_rocksDB_blockCacheSize [string,nullable] Size of RocksDB block-cache. For best performance, this cache should be big enough to hold a significant portion of the index database which can reach ~2GB in some cases. By default, it uses 10% of direct memory.
  ##
  dbStorage_rocksDB_blockCacheSize:
  ## @param config.dbStorage_rocksDB_blockSize
  ##
  dbStorage_rocksDB_blockSize: 65536
  ## @param config.dbStorage_rocksDB_bloomFilterBitsPerKey
  ##
  dbStorage_rocksDB_bloomFilterBitsPerKey: 10
  ## @param config.dbStorage_rocksDB_maxSizeInLevel1MB
  ##
  dbStorage_rocksDB_maxSizeInLevel1MB: 256
  ## @param config.dbStorage_rocksDB_numFilesInLevel0
  ##
  dbStorage_rocksDB_numFilesInLevel0: 4
  ## @param config.dbStorage_rocksDB_numLevels
  ##
  dbStorage_rocksDB_numLevels: -1
  ## @param config.dbStorage_rocksDB_sstSizeInMB
  ##
  dbStorage_rocksDB_sstSizeInMB: 64
  ## @param config.dbStorage_rocksDB_writeBufferSizeMB
  ##
  dbStorage_rocksDB_writeBufferSizeMB: 64
  ## @param config.dbStorage_writeCacheMaxSizeMb [string,nullable] Size of Write Cache. Memory is allocated from JVM direct memory. Write cache is used to buffer entries before flushing into the entry log. For good performance, it should be big enough to hold a substantial amount of entries in the flush interval.
  ##
  dbStorage_writeCacheMaxSizeMb:
  ## @param config.disableServerSocketBind Whether the bookie is allowed to disable bind on network interfaces. This bookie will be available only to BookKeeper clients executed on the local JVM.
  ##
  disableServerSocketBind:
  ## @param config.diskCheckInterval Disk check interval in milliseconds, interval to check the ledger dirs usage.
  ##
  diskCheckInterval: 10000
  ## @param config.diskUsageThreshold For each ledger dir, maximum disk space which can be used. Default is 0.95f. i.e. 95% of disk can be used at most after which nothing will be written to that  partition. If all ledger dir partitions are full, then bookie will turn to readonly mode if 'readOnlyModeEnabled=true' is set, else it will shutdown
  ##
  diskUsageThreshold:
  ## @param config.diskUsageWarnThreshold The disk free space low water mark threshold.
  ##
  diskUsageWarnThreshold:
  ## @param config.diskUsageLwmThreshold Set the disk free space low water mark threshold.
  ##
  diskUsageLwmThreshold:
  ## @param config.enableBusyWait Option to enable busy-wait settings. Default is false.
  ##
  enableBusyWait: false
  ## @param config.enableLocalTransport Whether the bookie is allowed to listen for the BookKeeper clients executed on the local JVM.
  ##
  enableLocalTransport:
  ## @param config.ensemblePlacementPolicy The ensemble placement policy used for re-replicating entries. Options: org.apache.bookkeeper.client.RackawareEnsemblePlacementPolicy or org.apache.bookkeeper.client.RegionAwareEnsemblePlacementPolicy
  ##
  ensemblePlacementPolicy: "org.apache.bookkeeper.client.RackawareEnsemblePlacementPolicy"
  ## @param config.entryLogFilePreallocationEnabled Enable or disable entry logger preallocation
  ##
  entryLogFilePreallocationEnabled: TRUE
  ## @param config.extraServerComponents [nullable] Configure a list of server components to enable and load on a bookie server.
  ##
  extraServerComponents:
  ## @param config.FileInfoFormatVersionToWrite
  ##
  FileInfoFormatVersionToWrite: 1
  ## @param config.flushEntrylogBytes Entry log flush interval in bytes. Flushing in smaller chunks but more frequently reduces spikes in disk I/O. Flushing too frequently may also affect performance negatively.
  ##
  flushEntrylogBytes: 268435456
  ## @param config.flushInterval How long the interval to flush ledger index pages to disk, in milliseconds. Flushing index files will introduce much random disk I/O. If separating journal dir and ledger dirs each on different devices, flushing would not affect performance. But if putting journal dir and ledger dirs on same device, performance degrade significantly on too frequent flushing. You can consider increment flush interval to get better performance, but you need to pay more time on bookie server restart after failure.
  ##
  flushInterval: 60000
  ## @param config.forceReadOnlyBookie Whether the bookie is force started in read only mode.
  ##
  forceReadOnlyBookie:
  ## @param config.gcOverreplicatedLedgerWaitTime How long the interval to trigger next garbage collection of overreplicated ledgers, in milliseconds. This should not be run very frequently since we read the metadata for all the ledgers on the bookie from zk.
  ##
  gcOverreplicatedLedgerWaitTime: 86400000
  ## @param config.gcWaitTime How long the interval to trigger next garbage collection, in milliseconds. Since garbage collection is running in background, too frequent gc will heart performance. It is better to give a higher number of gc interval if there is enough disk capacity.
  ##
  gcWaitTime: 900000
  ## @param config.httpServerClass The http server class.
  ##
  httpServerClass: "org.apache.bookkeeper.http.vertx.VertxHttpServer"
  ## @param config.httpServerEnabled The flag enables/disables starting the admin http server.
  ##
  httpServerEnabled: true
  ## @param config.httpServerPort The HTTP server port to listen on. By default, the value is 8080. If you want to keep it consistent with the Prometheus stats provider, you can set it to 8000.
  ##
  httpServerPort: 8080
  ## @param config.isForceGCAllowWhenNoSpace Whether force compaction is allowed when the disk is full or almost full. Forcing GC could get some space back, but could also fill up the disk space more quickly. This is because new log files are created before GC, while old garbage log files are deleted after GC.
  ##
  isForceGCAllowWhenNoSpace:
  ## @param config.isThrottleByBytes Throttle compaction by bytes or by entries.
  ##
  isThrottleByBytes: FALSE
  ## @param config.journalAdaptiveGroupWrites Whether to group journal force writes, which optimizes group commit for higher throughput.
  ##
  journalAdaptiveGroupWrites: TRUE
  ## @param config.journalAlignmentSize All the journal writes and commits should be aligned to given size
  ##
  journalAlignmentSize: 4096
  ## @param config.journalBufferedWritesThreshold Maximum writes to buffer to achieve grouping
  ##
  journalBufferedWritesThreshold: 524288
  ## @skip config.journalDirectories
  ## Directories that BookKeeper outputs its write ahead log. Multiple directories are available, being separated by ,. For example: journalDirectories=/tmp/bk-journal1,/tmp/bk-journal2. If journalDirectories is set, the bookies skip journalDirectory and use this setting directory.
  ##
  journalDirectories:
  ## @skip config.journalDirectory
  ## The directory where BookKeeper outputs its write-ahead log (WAL).
  ##
  journalDirectory:
  ## @param config.journalFlushWhenQueueEmpty If we should flush the journal when journal queue is empty
  ##
  journalFlushWhenQueueEmpty: FALSE
  ## @param config.journalFormatVersionToWrite The journal format version to write.
  ##
  journalFormatVersionToWrite: 6
  ## @param config.journalMaxBackups The max number of old journal files to keep. Keeping a number of old journal files would help data recovery in special cases.
  ##
  journalMaxBackups: 5
  ## @param config.journalMaxGroupWaitMSec The maximum latency to impose on a journal write to achieve grouping.
  ##
  journalMaxGroupWaitMSec: 1
  ## @param config.journalMaxSizeMB Max file size of journal file, in megabytes. A new journal file will be created when the old one reaches the file size limitation.
  ##
  journalMaxSizeMB: 2048
  ## @param config.journalPreAllocSizeMB How space to pre-allocate at a time in the journal.
  ##
  journalPreAllocSizeMB: 16
  ## @param config.journalRemoveFromPageCache Whether pages should be removed from the page cache after force write.
  ##
  journalRemoveFromPageCache: TRUE
  ## @param config.journalWriteBufferSizeKB The of the write buffers used for the journal.
  ##
  journalWriteBufferSizeKB: 64
  ## @param config.journalWriteData Should the data be written on journal. By default, data is written on journal for durability of writes.
  ##
  journalWriteData: true
  ## @param config.journalSyncData Should the data be fsynced on journal before acknowledgment. By default, data sync is enabled to guarantee durability of writes.
  ##
  journalSyncData: true
  ## @skip config.ledgerDirectories
  ## The directory where BookKeeper outputs ledger snapshots. This could define multiple directories to store snapshots separated by ,, for example ledgerDirectories=/tmp/bk1-data,/tmp/bk2-data. Ideally, ledger dirs and the journal dir are each in a different device, which reduces the contention between random I/O and sequential write. It is possible to run with a single disk, but performance will be significantly lower.
  ##
  ledgerDirectories:
  ## @param config.ledgerManagerType The type of ledger manager used to manage how ledgers are stored, managed, and garbage collected. See BookKeeper Internals for [more info](http://bookkeeper.apache.org/docs/latest/getting-started/concepts).
  ##
  ledgerManagerType:
  ## @param config.ledgerStorageClass Ledger storage implementation class
  ##
  ledgerStorageClass: "org.apache.bookkeeper.bookie.storage.ldb.DbLedgerStorage"
  ## @skip config.listeningInterface
  ## The network interface on which the bookie listens. By default, the bookie listens on all interfaces.
  ##
  listeningInterface:
  ## @param config.logSizeLimit Max file size of the entry logger, in bytes. A new entry log file will be created when the old one reaches the file size limitation.
  ##
  logSizeLimit: 1073741824
  ## @param config.lostBookieRecoveryDelay How long to wait, in seconds, before starting auto recovery of a lost bookie.
  ##
  lostBookieRecoveryDelay: 0
  ## @param config.majorCompactionInterval The time interval to run major compaction, in seconds. If set to less than zero, the major compaction is disabled. Note: should be greater than gcWaitTime.
  ##
  majorCompactionInterval: 86400
  ## @param config.majorCompactionThreshold The threshold of major compaction. Entry log files whose remaining size percentage reaches below this threshold will be compacted in a major compaction. Those entry log files whose remaining size percentage is still higher than the threshold will never be compacted. If set to less than zero, the minor compaction is disabled.
  ##
  majorCompactionThreshold: 0.5
  ## @param config.maxPendingAddRequestsPerThread The limited number of pending requests, which is used to avoid the executor queue to grow indefinitely when add workers threads are enabled.
  ##
  maxPendingAddRequestsPerThread: 10000
  ## @param config.maxPendingReadRequestsPerThread If read workers threads are enabled, limit the number of pending requests, to avoid the executor queue to grow indefinitely.
  ##
  maxPendingReadRequestsPerThread: 2500
  ## @skip config.metadataServiceUri
  ## metadata service uri that bookkeeper is used for loading corresponding metadata driver and resolving its metadata service location. Example: metadataServiceUri=metadata-store:zk:my-zk-1:2181
  ##
  metadataServiceUri:
  ## @param config.minorCompactionInterval Time interval to run minor compaction, in seconds. If set to less than zero, the minor compaction is disabled. Note: should be greater than gcWaitTime.
  ##
  minorCompactionInterval: 3600
  ## @param config.minorCompactionThreshold Threshold of minor compaction. Entry log files whose remaining size percentage reaches below this threshold will be compacted in a minor compaction. If set to less than zero, the minor compaction is disabled.
  ##
  minorCompactionThreshold: 0.2
  ## @param config.minUsableSizeForIndexFileCreation The minimum safe usable size available in index directory for bookie to create index files while replaying journal at the time of bookie starts in Readonly Mode (in bytes).
  ##
  minUsableSizeForIndexFileCreation: 1073741824
  ## @param config.nettyMaxFrameSizeBytes The maximum netty frame size in bytes. Any message received larger than this will be rejected.
  ##
  nettyMaxFrameSizeBytes: 5253120
  ## @param config.numAddWorkerThreads The number of threads that should handle write requests. if zero, the writes would be handled by netty threads directly.
  ##
  numAddWorkerThreads: 0
  ## @param config.numHighPriorityWorkerThreads The umber of threads that should be used for high priority requests (i.e. recovery reads and adds, and fencing).
  ##
  numHighPriorityWorkerThreads: 8
  ## @param config.numJournalCallbackThreads The number of threads that should handle journal callbacks
  ##
  numJournalCallbackThreads: 8
  ## @param config.numLongPollWorkerThreads The number of threads that should handle long poll requests.
  ##
  numLongPollWorkerThreads:
  ## @param config.numReadWorkerThreads The number of threads that should handle read requests. if zero, the reads would be handled by netty threads directly.
  ##
  numReadWorkerThreads: 8
  ## @param config.openFileLimit Max number of ledger index files could be opened in bookie server If number of ledger index files reaches this limitation, bookie server started to swap some ledgers from memory to disk. Too frequent swap will affect performance. You can tune this number to gain performance according your requirements.
  ##
  openFileLimit: 0
  ## @param config.openLedgerRereplicationGracePeriod The grace period, in milliseconds, that the replication worker waits before fencing and replicating a ledger fragment that's still being written to upon bookie failure.
  ##
  openLedgerRereplicationGracePeriod: 30000
  ## @param config.pageLimit How many index pages provided in ledger cache If number of index pages reaches this limitation, bookie server starts to swap some ledgers from memory to disk. You can increment this value when you found swap became more frequent. But make sure pageLimit*pageSize should not more than JVM max memory limitation, otherwise you would got OutOfMemoryException. In general, incrementing pageLimit, using smaller index page would gain better performance in lager number of ledgers with fewer entries case If pageLimit is -1, bookie server will use 1/3 of JVM memory to compute the limitation of number of index pages.
  ##
  pageLimit: 0
  ## @param config.pageSize Size of a index page in ledger cache, in bytes A larger index page can improve performance writing page to disk, which is efficient when you have small number of ledgers and these ledgers have similar number of entries. If you have large number of ledgers and each ledger has fewer entries, smaller index page would improve memory usage.
  ##
  pageSize:
  ## @param config.persistBookieStatusEnabled Persist the bookie status locally on the disks. So the bookies can keep their status upon restarts.
  ##
  persistBookieStatusEnabled:
  ## @param config.prometheusStatsHttpPort
  ##
  prometheusStatsHttpPort: 8000
  ## @param config.readBufferSizeBytes The number of bytes we should use as capacity for BufferedReadChannel.
  ##
  readBufferSizeBytes: 4096
  ## @param config.readOnlyModeEnabled If all ledger directories configured are full, then support only read requests for clients. If "readOnlyModeEnabled=true" then on all ledger disks full, bookie will be converted to read-only mode and serve only read requests. Otherwise the bookie will be shutdown. By default this will be disabled.
  ##
  readOnlyModeEnabled: TRUE
  ## @param config.readWorkerThreadsThrottlingEnabled IUse auto-throttling of the read-worker threads. This is done to ensure the bookie is not using unlimited amount of memory to respond to read-requests.
  ##
  readWorkerThreadsThrottlingEnabled: true
  ## @param config.reppDnsResolverClass Pulsar's metadata store based rack awareness solution
  ##
  reppDnsResolverClass: "org.apache.pulsar.zookeeper.ZkBookieRackAffinityMapping"
  ## @param config.rereplicationEntryBatchSize The number of max entries to keep in fragment for re-replication
  ##
  rereplicationEntryBatchSize: 100
  ## @param config.requestTimerNumTicks The number of ticks per wheel for the long poll request timer.
  ##
  requestTimerNumTicks:
  ## @param config.requestTimerTickDurationMs The tick duration in milliseconds for long poll requests.
  ##
  requestTimerTickDurationMs:
  ## @param config.serverSockKeepalive This setting is used to send keep-alive messages on connection-oriented sockets.
  ##
  serverSockKeepalive:
  ## @param config.serverTcpLinger The socket linger timeout on close. When enabled, a close or shutdown will not return until all queued messages for the socket have been successfully sent or the linger timeout has been reached. Otherwise, the call returns immediately and the closing is done in the background.
  ##
  serverTcpLinger:
  ## @param config.serverTcpNoDelay This settings is used to enabled/disabled Nagle’s algorithm, which is a means of improving the efficiency of TCP/IP networks by reducing the number of packets that need to be sent over the network. If you are sending many small messages, such that more than one can fit in a single IP packet, setting server.tcpnodelay to false to enable Nagle algorithm can provide better performance.
  ##
  serverTcpNoDelay: TRUE
  ## @param config.skipListArenaChunkSize The number of bytes that we should use as chunk allocation for org.apache.bookkeeper.bookie.SkipListArena.
  ##
  skipListArenaChunkSize:
  ## @param config.skipListArenaMaxAllocSize The maximum size that we should allocate from the skiplist arena. Allocations larger than this should be allocated directly by the VM to avoid fragmentation.
  ##
  skipListArenaMaxAllocSize:
  ## @param config.sortedLedgerStorageEnabled Whether sorted-ledger storage is enabled.
  ##
  sortedLedgerStorageEnabled:
  ## @param config.statsProviderClass
  ##
  statsProviderClass: "org.apache.bookkeeper.stats.prometheus.PrometheusMetricsProvider"
  ## @skip config.tlsProvider
  ## TLS Provider (JDK or OpenSSL).
  ##
  tlsProvider:
  ## @skip config.tlsProviderFactoryClass
  ## The path to the class that provides security.
  ##
  tlsProviderFactoryClass:
  ## @skip config.tlsClientAuthentication
  ## Type of security used by server.
  ##
  tlsClientAuthentication:
  ## @skip config.tlsHostnameVerificationEnabled
  ## Verify the hostname.
  ##
  tlsHostnameVerificationEnabled:
  ## @skip config.tlsKeyStoreType
  ## Bookie Keystore type.
  ##
  tlsKeyStoreType:
  ## @skip config.tlsKeyStore
  ##  Bookie Keystore location (path).
  ##
  tlsKeyStore:
  ## @skip config.tlsKeyStorePasswordPath
  ## Bookie Keystore password path, if the keystore is protected by a password.
  ##
  tlsKeyStorePasswordPath:
  ## @skip config.tlsTrustStoreType
  ## Bookie Truststore type.
  ##
  tlsTrustStoreType:
  ## @skip config.tlsTrustStore
  ## Bookie Truststore location (path).
  ##
  tlsTrustStore:
  ## @skip config.tlsTrustStorePasswordPath
  ## Bookie Truststore password path, if the trust store is protected by a password.
  ##
  tlsTrustStorePasswordPath:
  ## @param config.useHostNameAsBookieID Whether the bookie should use its hostname to register with the coordination service (e.g.: zookeeper service). When false, bookie will use its ip address for the registration.
  ##
  useHostNameAsBookieID: true
  ## @param config.useShortHostName If bookie is using hostname for registration and in ledger metadata then whether to use short hostname or FQDN hostname. Defaults to false.
  ##
  useShortHostName:
  ## @param config.useV2WireProtocol Use older Bookkeeper wire protocol (Before Version 3) for AutoRecovery
  ##
  useV2WireProtocol: false
  ## @param config.verifyMetadataOnGC True if the bookie should double check readMetadata prior to GC.
  ##
  verifyMetadataOnGC:
  ## @param config.writeBufferSizeBytes The number of bytes used as capacity for the write buffer
  ##
  writeBufferSizeBytes: 65536
  ## @param config.zkEnableSecurity Set ACLs on every node written on ZooKeeper, allowing users to read and write BookKeeper metadata stored on ZooKeeper. In order to make ACLs work you need to setup ZooKeeper JAAS authentication. All the bookies and Client need to share the same user, and this is usually done using Kerberos authentication. See ZooKeeper documentation.
  ##
  zkEnableSecurity:
  ## @param config.zkLedgersRootPath The root ZooKeeper path used to store ledger metadata. This parameter is used by the ZooKeeper-based ledger manager as a root znode to store all ledgers.
  ##
  zkLedgersRootPath: "/ledgers"
  ## @param config.zkRetryBackoffMaxMs The maximum time that the Zookeeper client backoff retries in milliseconds.
  ##
  zkRetryBackoffMaxMs:
  ## @param config.zkRetryBackoffStartMs The start time that the Zookeeper client backoff retries in milliseconds.
  ##
  zkRetryBackoffStartMs:
  ## @skip config.zkServers
  ## A list of one of more servers on which zookeeper is running. The server list can be comma separated values, for example: zkServers=zk1:2181,zk2:2181,zk3:2181.
  ##
  zkServers:
  ## @param config.zkTimeout ZooKeeper client session timeout in milliseconds Bookie server will exit if it received SESSION_EXPIRED because it was partitioned off from ZooKeeper for more than the session timeout JVM garbage collection, disk I/O will cause SESSION_EXPIRED. Increment this value could help avoiding this issue
  ##
  zkTimeout: 30000
  ## @param config.extraConfigValues [nullable] Additional config values
  ##
  extraConfigValues: {}

## @section Service parameters
## @descriptionStart
## Component application controller service and service account parameters. Note the data-store's service is headless because it only needs to communicate with other cluster components.
## @descriptionEnd
##
service:

  ports:
    ## @param service.ports.client [nullable] Component application controller unsecure service port
    ##
    client: 3181

    ## @param service.ports.clientTls [nullable] Component application controller unsecure service port
    ##
    clientTls: 3182

    ## @param service.ports.stateStorage [nullable] Port for function worker interactions when state storage is enabled
    ##
    stateStorage: 4181

  ## @param service.annotations [object,nullable] Additional custom annotations for Component application controller service
  ##
  annotations:

  ## @param service.extraPorts [array,nullable] Extra ports to expose (normally used with the `sidecar` value)
  ##
  extraPorts: []

## ServiceAccount configuration for the Component
##
serviceAccount:

  ## @param serviceAccount.name The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the common.names.name template
  name: ""

  ## @param serviceAccount.create Specifies whether a ServiceAccount should be created
  ##
  create: true

  ## @param serviceAccount.automountServiceAccountToken Automount service account token for the server service account
  ##
  automountServiceAccountToken: true

  ## @param serviceAccount.annotations [object,nullable] Annotations for service account. Evaluated as a template. Only used if `create` is `true`.
  ##
  annotations: {}

## @param podDisruptionBudget.enabled Enable the disruption budget
## @param podDisruptionBudget.maxUnavailable When enabled the maximum allowed unavailable for matchLabel objects
## @param podDisruptionBudget.minAvailable When enabled the min allowed available for matchLabel objects
##
podDisruptionBudget:
  enabled: true
  maxUnavailable: 1
  minAvailable:

## @section Other Parameters

## @param metricsServiceMonitor Enable component metrics scraping by creating a service monitor that is discoverable by Prometheus.
##
metricsServiceMonitor: false

## @param podManagementPolicy StatefulSet controller supports relax its ordering guarantees while preserving its uniqueness and identity guarantees. There are two valid pod management policies: OrderedReady and Parallel
## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
##
podManagementPolicy: Parallel

## @param updateStrategy.type Bookkeeper statefulset strategy type
## @param updateStrategy.rollingUpdate Bookkeeper statefulset rolling update configuration parameters
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
##
updateStrategy:
  type: RollingUpdate
  rollingUpdate: {}

## @param podLabels Extra labels for Bookkeeper pods
## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
##
podLabels: {}

## @param podAnnotations Extra annotations for Bookkeeper pods
## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
##
podAnnotations: {}

## @param hostAliases Bookkeeper pods host aliases
## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
##
hostAliases: []

## @param hostNetwork Specify if host network should be enabled for Bookkeeper pods
##
hostNetwork: false

## @param hostIPC Specify if host IPC should be enabled for Bookkeeper pods
##
hostIPC: false

## @param schedulerName Name of the k8s scheduler (other than default)
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
schedulerName: ""

## @param affinity Affinity for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set
##
affinity: {}

## @param podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
##
podAffinityPreset: ""

## @param podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
##
podAntiAffinityPreset: hard

## Node affinity preset
## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
##
nodeAffinityPreset:
  ## @param nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ##
  type: ""
  ## @param nodeAffinityPreset.key Node label key to match Ignored if `affinity` is set.
  ## E.g.
  ## key: "kubernetes.io/e2e-az-name"
  ##
  key: ""
  ## @param nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set.
  ## E.g.
  ## values:
  ##   - e2e-az1
  ##   - e2e-az2
  ##
  values: []

## @param nodeSelector Node labels for pod assignment
## Ref: https://kubernetes.io/docs/user-guide/node-selection/
##
nodeSelector: {}

## @param tolerations Tolerations for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: []

## @param topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
##
topologySpreadConstraints: []

## @param terminationGracePeriodSeconds Seconds the pod needs to gracefully terminate
## ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-handler-execution
##
terminationGracePeriodSeconds: 60

## @param priorityClassName Name of the existing priority class to be used by Bookkeeper pods
## Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/
##
priorityClassName: ""

## Bookkeeper pods' Security Context
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
## @param podSecurityContext.enabled Enable security context for the pods
## @param podSecurityContext.fsGroup Set Bookkeeper pod's Security Context fsGroup
##
podSecurityContext:
  enabled: true
  fsGroup: 1001

## Bookkeeper containers' Security Context
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
## @param containerSecurityContext.enabled Enable Bookkeeper containers' Security Context
## @param containerSecurityContext.runAsUser Set Bookkeeper containers' Security Context runAsUser
## @param containerSecurityContext.runAsNonRoot Set Bookkeeper containers' Security Context runAsNonRoot
## e.g:
##   containerSecurityContext:
##     enabled: true
##     capabilities:
##       drop: ["NET_RAW"]
##     readOnlyRootFilesystem: true
##
containerSecurityContext:
  enabled: true
  runAsUser: 1001
  runAsNonRoot: true

## @param containerCommand Override the container image ENTRYPOINT. Leave blank to use image default (if set)
##
containerCommand: ["sh", "-c", "exec /pulsar/bin/pulsar bookie"]

## @param containerArgs Override the container image CMD. Leave blank to use image default (if set)
##
containerArgs: []

## @param extraEnvVars Extra environment variables to add to the provisioning pod
## e.g:
## extraEnvVars:
##   - name: SOME_VALUE
##     value: "10"
##
extraEnvVars: []

## @param extraEnvVarsCM ConfigMap with extra environment variables
##
extraEnvVarsCM: ""

## @param extraEnvVarsSecret Secret with extra environment variables
##
extraEnvVarsSecret: ""

## @param initContainers Add additional Add init containers to the Bookkeeper pod(s)
## e.g:
## initContainers:
##   - name: your-image-name
##     image: your-image
##     imagePullPolicy: Always
##     ports:
##       - name: portname
##         containerPort: 1234
##
initContainers: []

containerPorts:

  ## @param containerPorts.client [nullable] Component application controller unsecure service port
  ##
  client: 3181

  ## @param containerPorts.clientTls [nullable] Component application controller unsecure service port
  ##
  clientTls: 3182

  ## @param containerPorts.stateStorage [nullable] Port for function worker interactions when state storage is enabled
  ##
  stateStorage: 4181

## @section Persistence parameters

## Enable persistence using Persistent Volume Claims
## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:

  ## @param persistence.enabled Enable data persistence
  ##
  enabled: true

  ## If this is enabled settings for individual disks will be ignored.
  ##
  oneDisk:
    ## @param persistence.oneDisk.enabled Combine the journals, ledgers, and ranges volumes into one. This overrides individual disk settings
    ##
    enabled: false

    ## @param persistence.oneDisk.existingClaim A manually managed Persistent Volume and Claim
    ## If defined, PVC must be created manually before volume will be bound
    ## The value is evaluated as a template
    ##
    existingClaim: ""

    ## @param persistence.oneDisk.mountPath The container mounting path
    ##
    mountPath: /pulsar/data/bookkeeper

    ## @param persistence.oneDisk.size PVC storage size
    ##
    size: 75Gi
  
    ## @param persistence.oneDisk.accessModes Persistent Volume Access Modes
    ##
    accessModes:
    - ReadWriteOnce

    ## @param persistence.oneDisk.storageClass PVC Storage Class for Kafka data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    storageClass:

    ## @param persistence.oneDisk.annotations Annotations for the PVC
    ##
    annotations: {}

    ## @param persistence.oneDisk.selector Selector to match an existing Persistent Volume. If set, the PVC can't have a PV dynamically provisioned for it
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}

  ## Journal storage settings
  ##
  journal:
  
    ## @param persistence.journal.mountPath The container mount path
    ##
    mountPath: /pulsar/data/bookkeeper/journal

    ## @param persistence.journal.size PVC storage size
    ##
    size: 20Gi
    
    ## @param persistence.journal.storageClass PVC Storage Class for Kafka data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    storageClass:

    ## @param persistence.journal.existingClaim A manually managed Persistent Volume and Claim
    ## If defined, PVC must be created manually before volume will be bound
    ## The value is evaluated as a template
    ##
    existingClaim: ""
  
    ## @param persistence.journal.accessModes Persistent Volume Access Modes
    ##
    accessModes:
    - ReadWriteOnce

    ## @param persistence.journal.annotations Annotations for the PVC
    ##
    annotations: {}

    ## @param persistence.journal.selector Selector to match an existing Persistent Volume. If set, the PVC can't have a PV dynamically provisioned for it
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}

  ## Ledgers storage settings
  ##
  ledgers:
  
    ## @param persistence.ledgers.mountPath The container mount path
    ##
    mountPath: /pulsar/data/bookkeeper/ledgers

    ## @param persistence.ledgers.size PVC storage size
    ##
    size: 50Gi
    
    ## @param persistence.ledgers.storageClass PVC Storage Class for Kafka data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    storageClass:

    ## @param persistence.ledgers.existingClaim A manually managed Persistent Volume and Claim
    ## If defined, PVC must be created manually before volume will be bound
    ## The value is evaluated as a template
    ##
    existingClaim: ""
  
    ## @param persistence.ledgers.accessModes Persistent Volume Access Modes
    ##
    accessModes:
    - ReadWriteOnce

    ## @param persistence.ledgers.annotations Annotations for the PVC
    ##
    annotations: {}

    ## @param persistence.ledgers.selector Selector to match an existing Persistent Volume. If set, the PVC can't have a PV dynamically provisioned for it
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}

  ## Ranges is used for functions state storage
  ##
  ranges:
  
    ## @param persistence.ranges.mountPath The container mount path
    ##
    mountPath: /pulsar/data/bookkeeper/ranges

    ## @param persistence.ranges.size PVC storage size
    ##
    size: 5Gi

    ## @param persistence.ranges.storageClass PVC Storage Class for data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    storageClass: "-"

    ## @param persistence.ranges.existingClaim A manually managed Persistent Volume and Claim
    ## If defined, PVC must be created manually before volume will be bound
    ## The value is evaluated as a template
    ##
    existingClaim: ""
  
    ## @param persistence.ranges.accessModes Persistent Volume Access Modes
    ##
    accessModes:
    - ReadWriteOnce

    ## @param persistence.ranges.annotations Annotations for the PVC
    ##
    annotations: {}

    ## @param persistence.ranges.selector Selector to match an existing Persistent Volume. If set, the PVC can't have a PV dynamically provisioned for it
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}

## Enable log persistence using Persistent Volume Claims
## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/
##
logPersistence:

  ## @param logPersistence.enabled Enable log storage
  ##
  enabled: false

  ## @param logPersistence.mountPath Mount path of Pulsar home
  ##
  mountPath: /pulsar/logs

  ## @param logPersistence.size PVC storage size
  ##
  size: 5Gi
  
  ## @param logPersistence.storageClass PVC Storage Class for Kafka data volume
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ## set, choosing the default provisioner.
  ##
  storageClass:

  ## @param logPersistence.existingClaim A manually managed Persistent Volume and Claim
  ## If defined, PVC must be created manually before volume will be bound
  ## The value is evaluated as a template
  ##
  existingClaim: ""

  ## @param logPersistence.accessModes Persistent Volume Access Modes
  ##
  accessModes:
    - ReadWriteOnce

  ## @param logPersistence.annotations Annotations for the PVC
  ##
  annotations: {}

  ## @param logPersistence.selector Selector to match an existing Persistent Volume. If set, the PVC can't have a PV dynamically provisioned for it
  ## selector:
  ##   matchLabels:
  ##     app: my-app
  ##
  selector: {}

## @section Pod Liveness & Readyness

## Configure extra options for Data Store containers' liveness, readiness and startup probes
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
## @param livenessProbe.enabled Enable livenessProbe on Data Store containers
## @param livenessProbe.exec.command Process to monitor for readiness
## @param livenessProbe.periodSeconds Period seconds for readinessProbe
## @param livenessProbe.timeoutSeconds Timeout seconds for readinessProbe
## @param livenessProbe.failureThreshold Failure threshold for readinessProbe
## @param livenessProbe.successThreshold Success threshold for readinessProbe
##
livenessProbe:
  enabled: true
  exec:
    command:
      - "/pulsar/probes/liveness.sh"
  periodSeconds: 3
  timeoutSeconds: 30
  failureThreshold: 5
  successThreshold: 1

## @param readinessProbe.enabled Enable readinessProbe on Data Store containers
## @param readinessProbe.exec.command Process to monitor for readiness
## @param readinessProbe.periodSeconds Period seconds for readinessProbe
## @param readinessProbe.failureThreshold Failure threshold for readinessProbe
## @param readinessProbe.successThreshold Success threshold for readinessProbe
##
readinessProbe:
  enabled: true
  exec:
    command:
      - "/pulsar/probes/readiness.sh"
  periodSeconds: 5
  failureThreshold: 1
  successThreshold: 1

## @param startupProbe.enabled Enable startupProbe on Data Store containers
## @param startupProbe.exec.command Process to monitor for readiness
## @param startupProbe.periodSeconds Period seconds for readinessProbe
## @param startupProbe.failureThreshold Failure threshold for readinessProbe
##
startupProbe:
  enabled: true
  exec:
    command:
      - "/pulsar/probes/startup.sh"
  periodSeconds: 3
  failureThreshold: 10

## @param lifecycleHooks lifecycleHooks for the Bookkeeper container to automate configuration before or after startup
##
lifecycleHooks: {}

## Bookkeeper resource requests and limits
## ref: https://kubernetes.io/docs/user-guide/compute-resources/
## @param resources.limits The resources limits for the container
##
resources:
  limits: {}

  requests:
    ## @param resources.requests.memory The requested resource memory for the container
    ##
    memory: 2Gi

    ## @param resources.requests.cpu The requested resource cpu for the container
    ##
    cpu: 1

## @param extraVolumes Optionally specify extra list of additional volumes for the Bookkeeper pod(s)
## e.g:
## extraVolumes:
##   - name: certs
##     secret:
##       secretName: admin-console-tls
##
##   - name: token-superuser
##     secret:
##       secretName: token-superuser
##
extraVolumes: []

## @param extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Bookkeeper container(s)
## extraVolumeMounts:
##    - name: certs
##      readOnly: true
##      mountPath: /pulsar/certs

##    - mountPath: "/pulsar/token-superuser"
##      name: token-superuser
##      readOnly: true
##
extraVolumeMounts: []

## @param sidecars Add additional sidecar containers to the Bookkeeper pod(s)
## e.g:
## sidecars:
##   - name: your-image-name
##     image: your-image
##     imagePullPolicy: Always
##     ports:
##       - name: portname
##         containerPort: 1234
##
sidecars: []
